# ç¤ºä¾‹åˆ—è¡¨
import os

import dotenv
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain_openai import ChatOpenAI

examples = [
    {"input": "2ğŸ¦œ2", "output": "4"},
    {"input": "2ğŸ¦œ3", "output": "8"},
]

# ç¤ºä¾‹æç¤ºè¯æ¨¡æ¿
example_prompt = ChatPromptTemplate.from_messages(
    [("human", "{input}æ˜¯å¤šå°‘ï¼Ÿ"), ("ai", "æ˜¯{output}")]
)

# å®šä¹‰å°‘æ ·æœ¬æç¤ºè¯æ¨¡æ¿
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt, examples=examples
)

# å®Œæ•´æç¤ºè¯æ¨¡æ¿
final_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ä½ æ˜¯ä¸€ä¸ªè®¡ç®—ä¸“å®¶"),
        few_shot_prompt,
        ("human", "{input}æ˜¯å¤šå°‘ï¼Ÿ"),
    ]
)

print(final_prompt.invoke({"input": "2ğŸ¦œ4"}).to_string())

dotenv.load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("DEEPSEEK_API_KEY")
os.environ["OPENAI_BASE_URL"] = os.getenv("DEEPSEEK_BASE_URL")

chat_model = ChatOpenAI(
    model="deepseek-chat",
)

response = chat_model.invoke(final_prompt.invoke({"input": "2ğŸ¦œ4"}))
print(response.content)


"""
System: ä½ æ˜¯ä¸€ä¸ªè®¡ç®—ä¸“å®¶
Human: 2ğŸ¦œ2æ˜¯å¤šå°‘ï¼Ÿ
AI: æ˜¯4
Human: 2ğŸ¦œ3æ˜¯å¤šå°‘ï¼Ÿ
AI: æ˜¯8
Human: 2ğŸ¦œ4æ˜¯å¤šå°‘ï¼Ÿ
æ˜¯16
"""